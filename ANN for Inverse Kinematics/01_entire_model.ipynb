{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch \n",
    "from torch import nn \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size and model save paths\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "PATH = 'Models/Final/01_Direct_10M/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1 (deg)</th>\n",
       "      <th>q2 (deg)</th>\n",
       "      <th>q3 (deg)</th>\n",
       "      <th>q4 (deg)</th>\n",
       "      <th>q5 (deg)</th>\n",
       "      <th>q6 (deg)</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.357874</td>\n",
       "      <td>0.537781</td>\n",
       "      <td>-0.179165</td>\n",
       "      <td>1.444722</td>\n",
       "      <td>0.403092</td>\n",
       "      <td>-6.954611</td>\n",
       "      <td>-0.139262</td>\n",
       "      <td>-0.174507</td>\n",
       "      <td>-0.243091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269199</td>\n",
       "      <td>-1.255875</td>\n",
       "      <td>-2.729479</td>\n",
       "      <td>1.578971</td>\n",
       "      <td>1.526988</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>-0.083841</td>\n",
       "      <td>0.090493</td>\n",
       "      <td>0.948361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.399324</td>\n",
       "      <td>0.737099</td>\n",
       "      <td>0.269215</td>\n",
       "      <td>-1.295048</td>\n",
       "      <td>1.105814</td>\n",
       "      <td>-1.595081</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>-0.058343</td>\n",
       "      <td>-0.095492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.630865</td>\n",
       "      <td>-0.393581</td>\n",
       "      <td>-0.569564</td>\n",
       "      <td>-2.048782</td>\n",
       "      <td>1.621882</td>\n",
       "      <td>-2.922093</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>-0.476409</td>\n",
       "      <td>0.299512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.624499</td>\n",
       "      <td>0.887666</td>\n",
       "      <td>-1.987815</td>\n",
       "      <td>-2.590494</td>\n",
       "      <td>0.107791</td>\n",
       "      <td>-3.599966</td>\n",
       "      <td>-0.603389</td>\n",
       "      <td>0.347365</td>\n",
       "      <td>-0.123526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q1 (deg)  q2 (deg)  q3 (deg)  q4 (deg)  q5 (deg)  q6 (deg)         x  \\\n",
       "0 -2.357874  0.537781 -0.179165  1.444722  0.403092 -6.954611 -0.139262   \n",
       "1 -0.269199 -1.255875 -2.729479  1.578971  1.526988  0.858804 -0.083841   \n",
       "2  0.399324  0.737099  0.269215 -1.295048  1.105814 -1.595081  0.005534   \n",
       "3 -0.630865 -0.393581 -0.569564 -2.048782  1.621882 -2.922093  0.554500   \n",
       "4  2.624499  0.887666 -1.987815 -2.590494  0.107791 -3.599966 -0.603389   \n",
       "\n",
       "          y         z  \n",
       "0 -0.174507 -0.243091  \n",
       "1  0.090493  0.948361  \n",
       "2 -0.058343 -0.095492  \n",
       "3 -0.476409  0.299512  \n",
       "4  0.347365 -0.123526  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "data = pd.read_csv('ik_dataset_4.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joint_0</th>\n",
       "      <th>joint_1</th>\n",
       "      <th>joint_2</th>\n",
       "      <th>joint_3</th>\n",
       "      <th>joint_4</th>\n",
       "      <th>joint_5</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.124733</td>\n",
       "      <td>0.654063</td>\n",
       "      <td>0.749052</td>\n",
       "      <td>0.706941</td>\n",
       "      <td>0.596231</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.420337</td>\n",
       "      <td>0.400196</td>\n",
       "      <td>0.130362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.457156</td>\n",
       "      <td>0.140218</td>\n",
       "      <td>0.227187</td>\n",
       "      <td>0.726171</td>\n",
       "      <td>0.864541</td>\n",
       "      <td>0.561507</td>\n",
       "      <td>0.452021</td>\n",
       "      <td>0.551658</td>\n",
       "      <td>0.870414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.563554</td>\n",
       "      <td>0.711163</td>\n",
       "      <td>0.840803</td>\n",
       "      <td>0.314498</td>\n",
       "      <td>0.763994</td>\n",
       "      <td>0.385761</td>\n",
       "      <td>0.503116</td>\n",
       "      <td>0.466590</td>\n",
       "      <td>0.222041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.399595</td>\n",
       "      <td>0.387247</td>\n",
       "      <td>0.669166</td>\n",
       "      <td>0.206534</td>\n",
       "      <td>0.887196</td>\n",
       "      <td>0.290720</td>\n",
       "      <td>0.816958</td>\n",
       "      <td>0.227642</td>\n",
       "      <td>0.467391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.917702</td>\n",
       "      <td>0.754298</td>\n",
       "      <td>0.378952</td>\n",
       "      <td>0.128939</td>\n",
       "      <td>0.525733</td>\n",
       "      <td>0.242171</td>\n",
       "      <td>0.154997</td>\n",
       "      <td>0.698475</td>\n",
       "      <td>0.204627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    joint_0   joint_1   joint_2   joint_3   joint_4   joint_5         x  \\\n",
       "0  0.124733  0.654063  0.749052  0.706941  0.596231  0.001913  0.420337   \n",
       "1  0.457156  0.140218  0.227187  0.726171  0.864541  0.561507  0.452021   \n",
       "2  0.563554  0.711163  0.840803  0.314498  0.763994  0.385761  0.503116   \n",
       "3  0.399595  0.387247  0.669166  0.206534  0.887196  0.290720  0.816958   \n",
       "4  0.917702  0.754298  0.378952  0.128939  0.525733  0.242171  0.154997   \n",
       "\n",
       "          y         z  \n",
       "0  0.400196  0.130362  \n",
       "1  0.551658  0.870414  \n",
       "2  0.466590  0.222041  \n",
       "3  0.227642  0.467391  \n",
       "4  0.698475  0.204627  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalising the data \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data))\n",
    "data.columns = ['joint_0','joint_1','joint_2','joint_3','joint_4','joint_5','x','y','z']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000000, 9), (2000000, 9))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train test split\n",
    "\n",
    "data_train, data_test = train_test_split(data, train_size=0.8, random_state=42)\n",
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device agnostic code\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8000000]), torch.Size([2000000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the data to tensors\n",
    "# We convert each column into seperate tensors and vertically stack them at the end so that more space is not used for each of the model\n",
    "\n",
    "# Train\n",
    "x_train = torch.Tensor(data_train['x'].to_numpy()).to(device)\n",
    "y_train = torch.Tensor(data_train['y'].to_numpy()).to(device)\n",
    "z_train = torch.Tensor(data_train['z'].to_numpy()).to(device)\n",
    "joint_0_train = torch.Tensor(data_train['joint_0'].to_numpy()).to(device)\n",
    "joint_1_train = torch.Tensor(data_train['joint_1'].to_numpy()).to(device)\n",
    "joint_2_train = torch.Tensor(data_train['joint_2'].to_numpy()).to(device)\n",
    "joint_3_train = torch.Tensor(data_train['joint_3'].to_numpy()).to(device)\n",
    "joint_4_train = torch.Tensor(data_train['joint_4'].to_numpy()).to(device)\n",
    "joint_5_train = torch.Tensor(data_train['joint_5'].to_numpy()).to(device)\n",
    "\n",
    "# Test\n",
    "x_test = torch.Tensor(data_test['x'].to_numpy()).to(device)\n",
    "y_test = torch.Tensor(data_test['y'].to_numpy()).to(device)\n",
    "z_test = torch.Tensor(data_test['z'].to_numpy()).to(device)\n",
    "joint_0_test = torch.Tensor(data_test['joint_0'].to_numpy()).to(device)\n",
    "joint_1_test = torch.Tensor(data_test['joint_1'].to_numpy()).to(device)\n",
    "joint_2_test = torch.Tensor(data_test['joint_2'].to_numpy()).to(device)\n",
    "joint_3_test = torch.Tensor(data_test['joint_3'].to_numpy()).to(device)\n",
    "joint_4_test = torch.Tensor(data_test['joint_4'].to_numpy()).to(device)\n",
    "joint_5_test = torch.Tensor(data_test['joint_5'].to_numpy()).to(device)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining the model \n",
    "\n",
    "class InverseKinematicsABBIRB140(nn.Module):\n",
    "    \n",
    "    \"\"\" This is a model structure specifically designed to calculate the inverse kinematics of the industrial robot ABB IRB 140, but can be used for any robot\n",
    "        This has a layer structure of input -> 64 -> 128 -> 64 -> output with non-linear activation and normalisation layers\n",
    "    Args:\n",
    "        input_features (int): defines the number of features given as input to the model\n",
    "        output_features (int): defines the number of features the model outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_features, output_features):\n",
    "        super().__init__()\n",
    "        self.layer_stack_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        self.layer_stack_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        self.layer_stack_3 = nn.Sequential(\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        self.layer_stack_4 = nn.Sequential(\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=128, out_features=output_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer_stack_1(x)\n",
    "        x = self.layer_stack_2(x)\n",
    "        x = self.layer_stack_3(x)\n",
    "        x = self.layer_stack_4(x)\n",
    "        return x   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training step\n",
    "def train_step(model: torch.nn.Module,\n",
    "               batch: tuple,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device = device):\n",
    "    \n",
    "    xtrain, ytrain = batch\n",
    "    xtrain, ytrain = xtrain.to(device), ytrain.to(device)\n",
    "    \n",
    "    model.train()\n",
    "    ypreds = model(xtrain)\n",
    "    loss = loss_fn(ypreds, ytrain)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print the training time\n",
    "\n",
    "def print_train_time(start:float, end:float, device:torch.device=None):\n",
    "    total_time = end-start\n",
    "    print(f\"Train time on device {device} : {total_time:.4f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the testing step\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              batch: tuple,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "    \n",
    "    xtest, ytest = batch\n",
    "    xtest, ytest = xtest.to(device), ytest.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        ypreds = model(xtest)\n",
    "        loss = loss_fn(ypreds, ytest)\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up model 0\n",
    "\n",
    "NAME_0 = 'model_0.pth'\n",
    "MODEL_SAVE_PATH_0 = PATH + NAME_0\n",
    "\n",
    "train_dataset = TensorDataset(torch.stack((x_train, y_train ,z_train), dim=1), torch.stack((joint_0_train, joint_1_train, joint_2_train, joint_3_train, joint_4_train, joint_5_train,), dim=1))\n",
    "test_dataset = TensorDataset(torch.stack((x_test, y_test ,z_test), dim=1), torch.stack((joint_0_test, joint_1_test, joint_2_test, joint_3_test, joint_4_test, joint_5_test, ), dim=1))\n",
    "\n",
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_dataloader = DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = InverseKinematicsABBIRB140(input_features=3, output_features=6).to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/6] (Training): 100%|██████████| 62500/62500 [05:32<00:00, 188.08it/s, Train Batch loss=0.0566, Train loss=0.0634]\n",
      "Epoch [1/6] (Testing) : 100%|██████████| 15625/15625 [00:45<00:00, 345.82it/s, Test batch loss=0.0558, Test loss=0.0591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/6] (Training): 100%|██████████| 62500/62500 [11:29<00:00, 90.60it/s, Train Batch loss=0.0584, Train loss=0.0615]   \n",
      "Epoch [2/6] (Testing) : 100%|██████████| 15625/15625 [00:45<00:00, 345.07it/s, Test batch loss=0.0558, Test loss=0.0592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/6] (Training): 100%|██████████| 62500/62500 [05:38<00:00, 184.89it/s, Train Batch loss=0.0621, Train loss=0.0614]\n",
      "Epoch [3/6] (Testing) : 100%|██████████| 15625/15625 [00:45<00:00, 345.31it/s, Test batch loss=0.057, Test loss=0.0592] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/6] (Training): 100%|██████████| 62500/62500 [09:37<00:00, 108.28it/s, Train Batch loss=0.0615, Train loss=0.0613]  \n",
      "Epoch [4/6] (Testing) : 100%|██████████| 15625/15625 [00:45<00:00, 344.01it/s, Test batch loss=0.056, Test loss=0.059] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/6] (Training): 100%|██████████| 62500/62500 [05:40<00:00, 183.82it/s, Train Batch loss=0.0648, Train loss=0.0613]\n",
      "Epoch [5/6] (Testing) : 100%|██████████| 15625/15625 [00:45<00:00, 344.97it/s, Test batch loss=0.0555, Test loss=0.059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/6] (Training): 100%|██████████| 62500/62500 [05:38<00:00, 184.65it/s, Train Batch loss=0.0667, Train loss=0.0612]\n",
      "Epoch [6/6] (Testing) : 100%|██████████| 15625/15625 [00:45<00:00, 342.85it/s, Test batch loss=0.0559, Test loss=0.059] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Train time on device cuda : 2887.9366 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training model 0\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start_model_0 = timer()\n",
    "epochs = 6\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(enumerate(train_dataloader), total=len(train_dataloader)) as t:\n",
    "\n",
    "        train_loss = 0\n",
    "        # Training loop\n",
    "        for i, batch in t:\n",
    "            batch_loss = train_step(model=model_0, batch=batch, loss_fn=loss_fn, optimizer=optimizer)\n",
    "            train_loss += batch_loss\n",
    "            t.set_description(f'Epoch [{epoch+1}/{epochs}] (Training)')\n",
    "            t.set_postfix({\n",
    "                'Train Batch loss': batch_loss,\n",
    "                'Train loss': train_loss/(i+1)\n",
    "            })\n",
    "                \n",
    "    with tqdm(enumerate(test_dataloader), total=len(test_dataloader)) as t:\n",
    "        test_loss = 0\n",
    "        # Testing loop\n",
    "        for i, batch in t:\n",
    "            batch_loss = test_step(model=model_0, batch=batch, loss_fn=loss_fn)\n",
    "            test_loss += batch_loss\n",
    "            t.set_description(f'Epoch [{epoch+1}/{epochs}] (Testing) ')\n",
    "            t.set_postfix({\n",
    "                'Test batch loss': batch_loss,\n",
    "                'Test loss': test_loss /(i+1)\n",
    "            })\n",
    "            \n",
    "    torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH_0)        \n",
    "      \n",
    "    print('---------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "train_time_end_model_0 = timer()\n",
    "train_time_model_0 = print_train_time(start=train_time_start_model_0, end=train_time_end_model_0, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
